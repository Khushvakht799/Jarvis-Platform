llama-cpp-python>=0.2.0
fastapi>=0.104.0
uvicorn>=0.24.0
grpcio>=1.60.0
requests>=2.31.0
psutil>=5.9.0
pydantic>=2.5.0
